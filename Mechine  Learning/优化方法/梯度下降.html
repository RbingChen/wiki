<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>梯度下降 - Knowledge Change Destiny</title>
        <meta name="keywords" content="Mechine Learning , Economics , Mathematics"/>
        <meta name="description" content="More Reading , More Possibilities"/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#Mechine  Learning">Mechine  Learning</a>&nbsp;»&nbsp;<a href="/wiki/#Mechine  Learning-优化方法">优化方法</a>&nbsp;»&nbsp;梯度下降</div>
</div>
<div class="clearfix"></div>
<div id="title">梯度下降</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#gradient-descent">一 Gradient Descent 为什么能求最小值？</a><ul>
<li><a href="#1">1.普通的梯度下降</a></li>
<li><a href="#2">2.二阶的梯度下降</a></li>
</ul>
</li>
<li><a href="#sgd-gd">二 SGD 和 GD</a></li>
<li><a href="#_1">三 梯度优化方法的改进</a></li>
</ul>
</div>
<h1 id="gradient-descent">一 Gradient Descent 为什么能求最小值？</h1>
<h2 id="1">1.普通的梯度下降</h2>
<p>首先考虑泰勒展开：<br />
$$<br />
f(x)=f(x_0)+f^{'}(x_0)(x-x_0)+\frac{f^{''}(x_0)}{2}(x-x_0)^2+......<br />
$$<br />
当$x,x_0$ 很接近的时候，近似等于：<br />
$$<br />
f(x)\approx f(x_0)+f^{'}(x_0)(x-x_0)<br />
$$<br />
这是一个一元二次函数，要函数减小，则可以有：<br />
$$<br />
1. f^{'}(x_0)&gt;0\ \ \ \ =&gt;\ \ \ \ x<x_0\\\\
2.f^{'}(x_0)<0\ \ \ \ =>\ \ \ \ x&gt;x_0<br />
$$<br />
可以表示为：<br />
$$<br />
x-x_0=-\alpha*f^{'}(x_0)<br />
$$</p>
<h2 id="2">2.二阶的梯度下降</h2>
<p>牛顿法，直接考虑二阶，这个时候是一个二次函数，二次函数的最小值：<br />
$$<br />
x=x_0-\frac{f^{'}(x_0)}{f^{''}(x_0)}<br />
$$<br />
对于多元函数，$f^{''}(x_0)$ 是一个矩阵，Hessian矩阵$H$。<br />
$$<br />
x=x_0-H^{-1}f^{'}(x_0)<br />
$$<br />
当变量较多的时候，$H^{-1}$ 的求解，很复杂。因此，延伸出拟牛顿法，目的是用近似的方法来计算Hessian矩阵的逆。</p>
<p>关于学习率的解释：泰勒展开是在$x_0$的很小的邻域内，如果$x$超过这个邻域，会导致推导不成立，函数值不会减小。</p>
<h1 id="sgd-gd">二 SGD 和 GD</h1>
<p>stochastic gradient descent ：考虑单个样本</p>
<p>gradient descent：考虑整体样本。</p>
<p>学习率的设置很关键</p>
<h1 id="_1">三 梯度优化方法的改进</h1>
</div>
<div id="income">
    <img src="/wiki/static/images/galaxy.jpg" alt="星空" style="max-width:300px;" />

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-12-18 23:41 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: '梯度下降',
  owner: 'RbingChen',
  repo: 'wiki',
  oauth: {
    client_id: '8d8c2034c8f3db5fd412',
    client_secret: 'b5dabd27e8c79eb5136fba7730d78f403ea54991',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 Cimon.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>