<!DOCTYPE HTML>
<html>
    <head>
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/style.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/css/tango.css">
        <link rel="Stylesheet" type="text/css" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/normalize.css">
        <link rel="stylesheet" href="/wiki/static/plugin/tipuesearch/css/tipuesearch.css">
        <link rel="shortcut icon" href="/wiki/favicon.ico" type="image/x-icon">
        <link rel="icon" href="/wiki/favicon.ico" type="image/x-icon">
        <title>bias Variance - Knowledge Change Destiny</title>
        <meta name="keywords" content="Mechine Learning , Economics , Mathematics"/>
        <meta name="description" content="More Reading , More Possibilities"/>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <meta name="viewport" content="width=device-width" />

        <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
          tex2jax: {inlineMath: [['$(',')$'], ['\\(','\\)'], ['$', '$']]}
        });
        </script>
        <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script src="https://code.jquery.com/jquery-2.2.4.min.js"
            integrity="sha256-BbhdlvQf/xTY9gja0Dq3HiwQF8LaCRTXxZKRutelT44="
            crossorigin="anonymous"></script>

        <!-- Google Adsense -->
        <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

          ga('create', 'UA-78529611-1', 'auto');
          ga('send', 'pageview');


            // Google Adsense Auto AD
            (adsbygoogle = window.adsbygoogle || []).push({});
            /*
             (adsbygoogle = window.adsbygoogle || []).push({
                  google_ad_client: "ca-pub-6300557868920774",
                  enable_page_level_ads: true
             });
             */
        </script>
    </head>

    <body>
        <div id="container">
            
<div id="header">
  <div id="post-nav"><a href="/wiki/">Home</a>&nbsp;»&nbsp;<a href="/wiki/#Mechine  Learning">Mechine  Learning</a>&nbsp;»&nbsp;bias Variance</div>
</div>
<div class="clearfix"></div>
<div id="title">bias Variance</div>
<div id="content">
  <div class="toc"><span class="toctitle">Table of Contents</span><ul>
<li><a href="#biasvariance">bias和variance</a><ul>
<li><a href="#1">1.直观定义</a></li>
<li><a href="#2">2.图定义</a></li>
<li><a href="#3">3.数学推导</a></li>
<li><a href="#4knn">4.kNN</a></li>
<li><a href="#5biasvariance">5.理解bias和Variance 对模型的影响</a><ul>
<li><a href="#51">5.1推广到训练集和测试集</a></li>
</ul>
</li>
<li><a href="#6rfgbdt">6.RF和GBDT</a></li>
<li><a href="#7">7 降低偏差必然提高方差？</a></li>
</ul>
</li>
</ul>
</div>
<h1 id="biasvariance">bias和variance</h1>
<p><a href="http://scott.fortmann-roe.com/docs/BiasVariance.html">Understanding the Bias-Variance Tradeoff</a></p>
<h2 id="1">1.直观定义</h2>
<p>Error due to Bias：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据。Bias 描述的是期望值和真实值的差值。如果只有一个模型，就没有什么期望值和均值可言（认为是不同训练集得到不同model）。</p>
<p>Error due to Variance：衡量多个模型预测值的差异程度。描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散。</p>
<p><strong>训练得到的不同模型的定义</strong>：1. 算法类型不同 ；2. 算法类型相同，参数不同；3.算法类型想听，参数相同，训练集不同。 对于树模型，可以使用不同的特征划分标准、不同的参数设置达到不同模型的目的。</p>
<p><strong>训练只得到一个模型，由公式可知误差来源是偏差。事实上，工程中，经常使用一个线性回归模型建模，那么讨论多个模型的意义是什么，单个模型，哪来的期望均值？</strong></p>
<p>可以认为是采样得到不同的训练集训练同一个模型。</p>
<p><strong>为什么简单的模型，bias高，Variance低？</strong></p>
<p>​     简单的模型，对数据的拟合能力有限，受数据影响小，每次换数据，预测值都差不多，Variance低，但是不能很好的拟合数据规律，导致bias大；复杂的模型强烈拟合数据规律，受数据影响大，换数据得到的模型，预测值差别大，Variance高，但是预测的期望值小。 </p>
<p><strong>为什么复杂模型，能更好的拟合数据？</strong></p>
<p>​    线性模型中，有3个参数的函数肯定被4个参数的函数涵盖，如果参数大于数据量的时候，严重过拟合，换数据得到的参数值都不同，解不唯一；树模型，数深度越深，模型越复杂，可以直到模型每个节点一个数据，严重的拟合数据。很好的拟合，不代表很好的泛化。</p>
<p><strong>有什么指导意义，会怎么用？</strong></p>
<p>比较测试集和训练集的误差。</p>
<ol>
<li>在训练集上误差小，在测试集上误差大。这是由于Variance大带来的误差，因为测试集和训练集是用一个数据分布的不同采样，由于模型过分拟合测试集上的数据规律（局部规律)，对于测试集上的数据和训练集整体相似，但存在不同，模型不能很好的预测，导致误差大；或者说，Variance。</li>
<li>在训练集上误差大，在测试集上误差大。说明，bias大。如果测试误差比训练集大很多，Variance大；差不多，bias小。这个时候，要提高模型复杂度，加特征。</li>
<li>在训练集上误差小，在测试集上误差小。说明，模型很work，bias 和Variance小。</li>
</ol>
<p>推广开来，就是模型复杂度越高</p>
<p><strong>rf，出发点？</strong></p>
<p>rf，降Variance，升Bias。</p>
<p>boosting，降Bias，升Variance。</p>
<p>决策树、神经网络等，训练样本稍加变化就会导致模型有显著变化；线性模型、支持向量机、朴素贝叶斯、k近邻等，对数据样本的扰动不敏感。</p>
<h2 id="2">2.图定义</h2>
<p>&lt;img   src="/wiki/static/images/bias_variance.png"   alt="bias variance图"</p>
<h2 id="3">3.数学推导</h2>
<p>现有数据$(Y,X)$，猜想有$Y=f(X)+\varepsilon$。其中，$\varepsilon \sim N(0,\sigma_{\varepsilon})$，用算法模型$\hat f(X)$对$f(X)$进行估计，有如下<strong>误差</strong>定义：<br />
$$<br />
Erro(x)=E[(y-\hat f(x))^2]<br />
$$<br />
可以进行如下分解：<br />
$$<br />
Erro=E[y^2-2y\hat f(x)+\hat f^2(x)]\\<br />
=E[y^2]-2E[y]E[\hat f(x)]+E[\hat f^2(x)]<br />
$$<br />
对于y而言，给定 x时，$f(x)$是一个定值，此时$y\sim N(f(x),\sigma_{\varepsilon})$。则有：<br />
$$<br />
E(y)=f(x)\\<br />
E(y^2)=\sigma_\varepsilon^2+f^2(x)<br />
$$<br />
对于上面等式：<br />
$$<br />
Erro=f^2(x)-2f(x)E[\hat f(x)]+E[\hat f(x)]^2-E[\hat f(x)]^2+E[\hat f^2(x)]+\sigma_\varepsilon^2<br />
$$<br />
最后可得：<br />
$$<br />
Erro=[f(x)-E(\hat f(x))]^2-E[(\hat f(x)-E[\hat f(x)])^2]++\sigma_\varepsilon^2<br />
$$<br />
可以认为是Bias的平方+Variance+Irreducible Erro。</p>
<h2 id="4knn">4.kNN</h2>
<p>首先，对于不同的训练样本都是从一个原始分布中采集出来的。</p>
<p>当k很小，或者为1 的时候，此时，bias很小，但是Variance很大。</p>
<p>​     <strong>解释：</strong>对于不同样本，训练得到的模型。对于新的样本，每个模型的预测值，存在一定误差，但是预测值的偏差会较低。可以这么这么理解。假设实际值时0，每个模型的误差分别为：$(12,-8,8,-12....)$，平均下来可能是接近于0的数，但是他们的方差$[12^2+(-23)^2+23^2+(-12)^2]$很大。</p>
<p>当k很大时候，此时，bias很大，但是Variance很小。</p>
<p><strong>解释：</strong>对于knn来说，k越大，有更多的值加入进行预测，预测的结果更偏向稳定(对于knn回归，中心极限定理可得，k越大，样本的均值，趋向于某个固定值)，此时每个模型，预测值都比较有限。但是这个时候每个模型的误差可能会更大，同上，预测误差为，$(17,18,20,17...)$，这个时候整体的误差$(18)$较大，方差$(1^2+0+4+1)$偏小。</p>
<p>那么，需要做一个tradeoff 。</p>
<h2 id="5biasvariance">5.理解bias和Variance 对模型的影响</h2>
<p>Bias大，模型预测值不准，</p>
<p>Variance大，不同模型之间预测值差别大。</p>
<p>直观的感觉：Bias小，但是Variance大的模型，貌似更可以接受。但实际上，一般只有一个模型。因此，需要同时对Bias和Variance做到极致的小。</p>
<h3 id="51">5.1推广到训练集和测试集</h3>
<p>有两个数据集A和B，采集自同一个样本分布。</p>
<p>1.在数据集A上，使用算法训练得到模型，如果拟合程度很深，数据集A上误差很小，认为bias很小；但在数据集B进行预测，误差会很大，因为模型过度拟合了数据集B上的分布，两个数据上存在差异，导致模型无法很好的预测数据集B上的数据，导致误差很大，这种误差，认为是Variance很大带来的。</p>
<p>为什么Bias很小可以理解，但为什么是Variance很大呢？</p>
<p>​        如果使用算法去拟合数据集B，得到模型。该模型</p>
<h2 id="6rfgbdt">6.RF和GBDT</h2>
<p>减小Variance，增加Bias？</p>
<p>​        假设每个树分裂到极致，每一个叶节点是一个预测值，这种情况下。对于不同训练样本而言，训练得到不同的模型。预测给点值时，这些模型预测的值的期望值或者均值，相关对于真实值来说，bias比较小。但是每个模型预测值的差异很大。</p>
<p>理论上，有无穷样本时，RF是无偏的。</p>
<h2 id="7">7 降低偏差必然提高方差？</h2>
<p>为什么说，bias低就是过拟合了？给点，测试集上，</p>
</div>
<div id="income">
    <img src="/wiki/static/images/galaxy.jpg" alt="星空" style="max-width:300px;" />

    <ins class="adsbygoogle"
     style="display:block; text-align:center;"
     data-ad-layout="in-article"
     data-ad-format="fluid"
     data-ad-client="ca-pub-6300557868920774"
     data-ad-slot="6882414849"></ins>
</div>
<div id="content-footer">created in <span class="create-date date"> 2018-12-17 10:14 </span></div>

<div id="comments"></div>
<link rel="stylesheet" href="https://imsun.github.io/gitment/style/default.css">
<script src="https://imsun.github.io/gitment/dist/gitment.browser.js"></script>
<script type="text/javascript">
const gitment = new Gitment({
  id: location.pathname,
  title: 'bias Variance',
  owner: 'RbingChen',
  repo: 'wiki',
  oauth: {
    client_id: '8d8c2034c8f3db5fd412',
    client_secret: 'b5dabd27e8c79eb5136fba7730d78f403ea54991',
  },
  // ...
  // For more available options, check out the documentation below
})

gitment.render('comments')
// or
// gitment.render(document.getElementById('comments'))
// or
// document.body.appendChild(gitment.render())
</script>

        </div>
        <div id="footer">
            <span>
                Copyright © 2018 Cimon.
                Powered by <a href="http://simiki.org/" target="_blank">Simiki</a>.
            </span>
        </div>
        

        <script>
        var _hmt = _hmt || [];
        (function() {
          var hm = document.createElement("script");
          hm.src = "https://hm.baidu.com/hm.js?df74779713027375e7b79302fb72d7b0";
          var s = document.getElementsByTagName("script")[0];
          s.parentNode.insertBefore(hm, s);
        })();
        </script>


        <script src="/wiki/tipuesearch_content.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch_set.js"></script>
        <script src="/wiki/static/plugin/tipuesearch/tipuesearch.min.js"></script>
    </body>
</html>