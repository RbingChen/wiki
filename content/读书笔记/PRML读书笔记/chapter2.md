---
title : "chapter2-概率分布"
layout : page
date : 2019-04-16 16:44
---

[TOC]



# 零.前置

`Density Estimation`(密度估计)：给定数据集，估计任一单样本$x$出现的概率。

`共轭先验`：保证`后验概率`分布和先验概率分布有`相同的函数式`。=>>被频率学派吐槽点，先验选择完全为了计算方便。



# 一.二变量

## 1.1 伯努利分布

概率分布：$p(x)=\mu^x(1-\mu)^{1-x}$

似然函数：$p(D|\mu)=\prod_{i=1}^n \mu^{x_i}(1-\mu)^{1-x_i}=\mu^{\sum_{i=1}^n x_i}(1-\mu)^{n-\sum_{i=1}^n x_i}$

## 1.2二项式分布

如果一个随机变量$x$服从伯努利分布，则实验组$n$次，有$m$次成功的概率服从分布：

$p(m,n)=C(m,n)\mu^m (1-\mu)^{n-m}$ 

上式可以看成是似然函数，与伯努利分布的似然函数式是**等价**的。

`先验分布`使用`Beta分布`:$Beta(\mu|a,b)=\frac{\Gamma (a+b)}{\Gamma (a)+\Gamma(b)}\mu^{a-1}(1-\mu)^{b-1}$

`后验分布`:$p(u|a,b,m,n)=\frac{\Gamma (a+b)}{\Gamma (a)+\Gamma(b)}\mu^{m+a-1}(1-\mu)^{n-m+b-1}$

如何理解后验分布？

​       可以把a和b看成是已知的实验结果，并在这个结果继续用于后续的实验。或者说，用先有的知识校正似然函数。进一步，对于批处理数据，可以认为之前的数据是先验知识，用以校正当前数据对参数的概率预测。

​       `Sequential approach`

推断：$p(x=1|D)=\int  p(x=1|\mu)  p(\mu|D) d\mu=\frac{m+a}{n+a+b}$，当数据了很大时，和MLE的估计值是相近的。

## 1.3与二分类问题比较

可以看成是概率是离散值的二分类问题。sigmoid是把概率映射到[0,1]的连续空间。

# 二.多变量



# 三.高斯分布

实质上是在找一个方法把   $(x-\mu)^T\sum ^{-1}(x-\mu)$变成$y^Ty$的形式。



$g_i、h_i$ 表示误差(错误率等）相关关的函数，$i$表示不同的样本，$I_L$表示左边的节点（树的左子树），$I_L$，表示右边的节点（树的右子树），$\lambda 、\gamma$表示平滑因子，为了让模型更稳定。给定一个特征值，对所有样本计算出$g_i、h_i$这两个值，再计算出$L_{split}$值，选择$L_{split}$最大特征值作为划分特征；然后依次再对左子树和右子树做同样的操作，直到算法收敛。

# 四.指数族



# 五.非信息先验

先验分布会把先验信息（知识）传递到概率推断过程。但是如果我们把变量的出现某些值的先验概率置成0，那将会导致这些后验概率也会是0，这将会导致怎么`推断过程和观测数据无关`，是不科学的。因此，我们要找一种分布，对后验分布有极小的影响，这种分布叫做非信息先验(`noninformative priors`)

个人看来：` 这有点强制先验的赶脚。换句话说，当我们不需要先验知识的时候，不能认为先验概率是0，因为这样会导致，变量的值的后验概率为0，因此需要找一个先验分布，对所有的变量的所有值一视同仁。提出这么一个分布，是为了保证推断的过程符合beysian框架的一般性`



直观的做法，使用均匀分布，但是均匀分布，在做变量变化是会改变这个特性。$p_\lambda(\lambda)=a,\lambda=\eta^2$，那么得到如下：
$$
p_\eta(\eta)=p_\lambda(\lambda)|\frac{d \lambda}{d\eta}|=p_\lambda(\eta^2)2\eta\propto\eta
$$
提取两种noninformative prior，

一种是`平移不变性`（translation invariance)，满足如下条件：

$p(x|\mu)=f(x-\mu),\hat x=x+c,p(\hat x|\hat\mu)=f(\hat x-\hat\mu)$。其中，有$\hat \mu=\mu+c$。

另一种是`缩放不变性( scale  invariance)`，满足如下条件：

$p(x|\sigma)=\frac{1}{\sigma}f(\frac{x}{\sigma}),\hat x=cx,p(\hat x|\hat\sigma)=\frac{1}{\hat \sigma}f(\frac{\hat x}{\hat \sigma})$。 其中，有$\hat \sigma=c\sigma$。

**有什么用？**

   呃，个人觉得没什么用，只是为了保证计算满足整个beysian的框架。