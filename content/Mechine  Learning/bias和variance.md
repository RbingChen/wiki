---
title : "bias Variance"
layout : page
date : 2018-12-17 10:14
---



[TOC]



#  bias和variance



[Understanding the Bias-Variance Tradeoff](http://scott.fortmann-roe.com/docs/BiasVariance.html)

## 1.直观定义

 Error due to Bias：描述的是预测值（估计值）的期望与真实值之间的差距。偏差越大，越偏离真实数据。Bias 描述的是期望值和真实值的差值。如果只有一个模型，就没有什么期望值和均值可言（认为是不同训练集得到不同model）。

Error due to Variance：衡量多个模型预测值的差异程度。描述的是预测值的变化范围，离散程度，也就是离其期望值的距离。方差越大，数据的分布越分散。

**训练得到的不同模型的定义**：1. 算法类型不同 ；2. 算法类型相同，参数不同；3.算法类型想听，参数相同，训练集不同。 对于树模型，可以使用不同的特征划分标准、不同的参数设置达到不同模型的目的。

**训练只得到一个模型，由公式可知误差来源是偏差。事实上，工程中，经常使用一个线性回归模型建模，那么讨论多个模型的意义是什么，单个模型，哪来的期望均值？**

  可以认为是采样得到不同的训练集训练同一个模型。

**为什么简单的模型，bias高，Variance低？**

​     简单的模型，对数据的拟合能力有限，受数据影响小，每次换数据，预测值都差不多，Variance低，但是不能很好的拟合数据规律，导致bias大；复杂的模型强烈拟合数据规律，受数据影响大，换数据得到的模型，预测值差别大，Variance高，但是预测的期望值小。 

**为什么复杂模型，能更好的拟合数据？**

​    线性模型中，有3个参数的函数肯定被4个参数的函数涵盖，如果参数大于数据量的时候，严重过拟合，换数据得到的参数值都不同，解不唯一；树模型，数深度越深，模型越复杂，可以直到模型每个节点一个数据，严重的拟合数据。很好的拟合，不代表很好的泛化。

**有什么指导意义，会怎么用？**

 比较测试集和训练集的误差。

1. 在训练集上误差小，在测试集上误差大。这是由于Variance大带来的误差，因为测试集和训练集是用一个数据分布的不同采样，由于模型过分拟合测试集上的数据规律（局部规律)，对于测试集上的数据和训练集整体相似，但存在不同，模型不能很好的预测，导致误差大；或者说，Variance。
2. 在训练集上误差大，在测试集上误差大。说明，bias大。如果测试误差比训练集大很多，Variance大；差不多，bias小。这个时候，要提高模型复杂度，加特征。
3. 在训练集上误差小，在测试集上误差小。说明，模型很work，bias 和Variance小。

推广开来，就是模型复杂度越高

**rf，出发点？**

 rf，降Variance，升Bias。

 boosting，降Bias，升Variance。

决策树、神经网络等，训练样本稍加变化就会导致模型有显著变化；线性模型、支持向量机、朴素贝叶斯、k近邻等，对数据样本的扰动不敏感。

## 2.图定义

   <img   src="/wiki/static/images/bias_variance.png"   alt="bias variance图"



## 3.数学推导

现有数据$(Y,X)$，猜想有$Y=f(X)+\varepsilon$。其中，$\varepsilon \sim N(0,\sigma_{\varepsilon})$，用算法模型$\hat f(X)$对$f(X)$进行估计，有如下**误差**定义：
$$
Erro(x)=E[(y-\hat f(x))^2]
$$
可以进行如下分解：
$$
Erro=E[y^2-2y\hat f(x)+\hat f^2(x)]\\\\
=E[y^2]-2E[y]E[\hat f(x)]+E[\hat f^2(x)]
$$
对于y而言，给定 x时，$f(x)$是一个定值，此时$y\sim N(f(x),\sigma_{\varepsilon})$。则有：
$$
E(y)=f(x)\\\\
E(y^2)=\sigma_\varepsilon^2+f^2(x)
$$
对于上面等式：
$$
Erro=f^2(x)-2f(x)E[\hat f(x)]+E[\hat f(x)]^2-E[\hat f(x)]^2+E[\hat f^2(x)]+\sigma_\varepsilon^2
$$
最后可得：
$$
Erro=[f(x)-E(\hat f(x))]^2-E[(\hat f(x)-E[\hat f(x)])^2]++\sigma_\varepsilon^2
$$
可以认为是Bias的平方+Variance+Irreducible Erro。



## 4.kNN

首先，对于不同的训练样本都是从一个原始分布中采集出来的。

当k很小，或者为1 的时候，此时，bias很小，但是Variance很大。

​     **解释：**对于不同样本，训练得到的模型。对于新的样本，每个模型的预测值，存在一定误差，但是预测值的偏差会较低。可以这么这么理解。假设实际值时0，每个模型的误差分别为：$(12,-8,8,-12....)$，平均下来可能是接近于0的数，但是他们的方差$[12^2+(-23)^2+23^2+(-12)^2]$很大。

当k很大时候，此时，bias很大，但是Variance很小。

   **解释：**对于knn来说，k越大，有更多的值加入进行预测，预测的结果更偏向稳定(对于knn回归，中心极限定理可得，k越大，样本的均值，趋向于某个固定值)，此时每个模型，预测值都比较有限。但是这个时候每个模型的误差可能会更大，同上，预测误差为，$(17,18,20,17...)$，这个时候整体的误差$(18)$较大，方差$(1^2+0+4+1)$偏小。

   那么，需要做一个tradeoff 。



## 5.理解bias和Variance 对模型的影响

Bias大，模型预测值不准，

Variance大，不同模型之间预测值差别大。

直观的感觉：Bias小，但是Variance大的模型，貌似更可以接受。但实际上，一般只有一个模型。因此，需要同时对Bias和Variance做到极致的小。



### 5.1推广到训练集和测试集

有两个数据集A和B，采集自同一个样本分布。

1.在数据集A上，使用算法训练得到模型，如果拟合程度很深，数据集A上误差很小，认为bias很小；但在数据集B进行预测，误差会很大，因为模型过度拟合了数据集B上的分布，两个数据上存在差异，导致模型无法很好的预测数据集B上的数据，导致误差很大，这种误差，认为是Variance很大带来的。

为什么Bias很小可以理解，但为什么是Variance很大呢？

​        如果使用算法去拟合数据集B，得到模型。该模型

## 6.RF和GBDT

减小Variance，增加Bias？

​        假设每个树分裂到极致，每一个叶节点是一个预测值，这种情况下。对于不同训练样本而言，训练得到不同的模型。预测给点值时，这些模型预测的值的期望值或者均值，相关对于真实值来说，bias比较小。但是每个模型预测值的差异很大。



理论上，有无穷样本时，RF是无偏的。



## 7 降低偏差必然提高方差？







为什么说，bias低就是过拟合了？给点，测试集上，